---
title: ""
author: ""
toc: false
output:
  pdf_document: default
toc-title: Contenido
execute:
  warning: false
  message: false
editor_options: 
  markdown: 
    wrap: sentence
---

\thispagestyle{empty}

\begin{center}
  \vspace*{1cm}

  \Huge
  \textbf{Trabajo Práctico: Estadística Actuarial}

  \vspace{0.5cm}
  \LARGE

  \vspace{1.5cm}

  \textbf{Alumnos:}  Malena Irisarri, Román Landa\\

  \vfill

  \includegraphics[width=0.9\textwidth]{img/logo_universidad.jpg}

  \vspace{0.8cm}


  Rosario, Argentina

  10 de Mayo de 2025
\end{center}

\newpage

# Introducción

En el sector asegurador, garantizar la solvencia financiera es fundamental para cumplir con las obligaciones frente a los asegurados y mantener la estabilidad de la compañía. En este contexto, el Margen de Solvencia Mínimo (MSM) emerge como un indicador clave que asegura la capacidad de la aseguradora para afrontar siniestros inesperados, incluso en escenarios adversos. 

Para este trabajo, se analizará la sub-cartera de pólizas de seguros automotores de una compañía, compuesta por 25.615 pólizas, con el objetivo de determinar el MSM que permita alcanzar una Probabilidad de Solvencia del 99% durante el año 2024. El análisis se basará en datos históricos de siniestros de los años 2021, 2022 y 2023, considerando ajustes por inflación mediante la serie CER publicado en [Banco Central de la República Argentina (BCRA)](https://www.bcra.gob.ar/PublicacionesEstadisticas/Principales_variables.asp). Adicionalmente, se explorarán diferentes distribuciones de probabilidad, para modelar el comportamiento de los siniestros y se probarán distintos recargos de seguridad sobre las primas puras.

Este informe presentará alternativas para el cálculo del MSM bajo el importante supuesto de que **durante el año 2024, la cantidad de pólizas y el perfil de las mismas, no cambiará.** El objetivo final es asegurar la estabilidad financiera y cumplir con los requisitos regulatorios de la Superintendencia de Seguros de la Nación (SSN).



```{r include=FALSE}
library(readxl)
library(dplyr)
library(fitdistrplus)
library(actuar)
library(ggplot2)
library(lubridate)
library(e1071)
library(knitr)
library(kableExtra)
```

# Datos

Contamos con una base de datos que contiene 3431 cuantías pagadas durante el año 2023. A ellas les aplicamos la actualización por CER llevando todos los valores al día 01-01-2024 para poder compararlos aplicando:

$$
\text{Cuantia Actualizada}_i = \text{Cuantia Original}_i \times \frac{\text{CER}_{\text{01/01/2024}}}{\text{CER}_i}
$$




```{r echo=FALSE, warning=FALSE}
cuantias_23 <- read_excel("Trabajo Final 2024 Base de Datos .xlsx", 
                          col_types = c("date", "numeric"))
cer23 <- read_excel("cer23.xlsx", 
                    col_types = c("date", "numeric"))


cuantias_23 <- cuantias_23 %>%
  left_join(cer23, by = "Fecha")

cuantias_23 <- cuantias_23 %>%
  mutate(cuantia24 = `Cuantia` * (cer23$ValorCER[366]/ValorCER))
```


```{r echo=FALSE, warning=FALSE}
tabla_cunatia <- cuantias_23
colnames(tabla_cunatia) <- c('Fecha','Cuantía', 'Valor CER', 'Cuantía Actualizada')

head(tabla_cunatia, 10) %>%
  kbl(caption = "Cuantías Pagadas en 2023.", 
      align = "c",
      format = "latex",  # Especificar formato LaTeX para PDF
      booktabs = TRUE) %>%  # Mejor formato para tablas en PDF
  kable_styling(
    latex_options = c("striped", "hold_position", "scale_down"),  # Opciones específicas para PDF
    full_width = FALSE,
    position = "center") %>% 
  row_spec(0, background = "#66CDAA", bold = TRUE)
```


\newpage

# Análisis Descriptivo

Realizamos un breve análisis descriptivo para observar cuál fue la frecuencia y la severidad durante 2023.

```{r echo=FALSE, out.width="90%"}
######################## DESCRIPTIVO ##################################
# Crear columna con el mes en formato año-mes

cuantias_23 <- cuantias_23 %>%
  mutate(mes = format(as.Date(Fecha), "%Y-%m"))
ggplot(cuantias_23, aes(x = mes)) +
  geom_bar(fill = "#66CDAA") +
  labs(title = "Cantidad de cuantías pagadas por mes (frecuencia)",
       x = "Mes",
       y = "Cantidad de pagos") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


```{r echo=FALSE, out.width="90%"}
####################

ggplot(cuantias_23, aes(x = cuantia24)) +
  geom_histogram(fill = "#66CDAA", bins = 60, color = "white") +
  labs(title = "Distribución de las cuantías actualizadas (severidad)",
       x = "Cuantía Actualizada",
       y = "Frecuencia") +
  theme_minimal()+
  coord_cartesian(xlim = c(0, 2000000))
```

```{r include=FALSE}
median(cuantias_23$cuantia24)
mean(cuantias_23$cuantia24)
sd(cuantias_23$cuantia24)
```

En estos gráficos podemos observar que la frecuencia parece constante a lo largo del periodo de análisis y que la severidad parece distribuirse de forma asimétrica con muchos siniestros pequeños y algunos pocos de gran importe. 

Además, podemos ver que al menos el 50% de los siniestros le costaron menos de \$ 417.603,40.- a la compañia y que el costo medio de los mismos fue de \$ 454.566,30.- con un desvio estandar de \$ 233.500,60.- 


# Simulaciones

Para predecir el monto esperado de siniestros y calcular el margen de solvencia, simularemos la frecuencia (número de siniestros) y la severidad (monto por siniestro), probando distintas combinaciones de distribuciones.

Comenzamos analizando qué distribución se ajusta mejor a nuestra severidad observada. 

El siguiente gráfico compara los datos reales con las distribuciones candidatas (Log-Normal, Weibull, Pareto y Burr):

```{r echo=FALSE, message=FALSE, warning=FALSE}
datos <- na.omit(cuantias_23$cuantia24)

# Ajustes
ajuste_lnorm <- fitdist(datos, "lnorm")
ajuste_weibull <- fitdist(datos, "weibull")
ajuste_burr <- fitdist(datos, "burr", start = list(shape1 = 2, shape2 = 2, rate = 2))
ajuste_pareto <- fitdist(datos, "pareto", start = list(shape = 2, scale = min(datos)))


ggplot(data.frame(x = datos), aes(x = x)) +
  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = "#66CDAA", color = "black", alpha = 0.6) +

  # --- Todas las líneas en tipo "solid" (continua) y tamaño 0.7 (más fino) ---
  stat_function(fun = dlnorm,
                args = list(meanlog = ajuste_lnorm$estimate["meanlog"],
                            sdlog = ajuste_lnorm$estimate["sdlog"]),
                aes(color = "Log-normal", linetype = "Log-normal"),
                size = 0.7) + # Más fina
  stat_function(fun = dweibull,
                args = list(shape = ajuste_weibull$estimate["shape"],
                            scale = ajuste_weibull$estimate["scale"]),
                aes(color = "Weibull", linetype = "Weibull"),
                size = 0.7) + # Más fina
  stat_function(fun = dburr,
                args = list(shape1 = ajuste_burr$estimate["shape1"],
                            shape2 = ajuste_burr$estimate["shape2"],
                            rate = ajuste_burr$estimate["rate"]),
                aes(color = "Burr", linetype = "Burr"),
                size = 0.7) + # Más fina
  stat_function(fun = dpareto,
                args = list(shape = ajuste_pareto$estimate["shape"],
                            scale = ajuste_pareto$estimate["scale"]),
                aes(color = "Pareto", linetype = "Pareto"),
                size = 0.7) + # Más fina

  # --- Personalización de colores y tipos de línea en la leyenda ---
  scale_color_manual(name = "Distribución",
                     values = c("Log-normal" = "darkblue",
                                "Weibull" = "#5F9EA0",
                                "Burr" = "#8B0A50",
                                "Pareto" = "#CD5555")) +
  scale_linetype_manual(name = "Distribución",
                        values = c("Log-normal" = "solid", # Todas "solid"
                                   "Weibull" = "solid",
                                   "Burr" = "solid",
                                   "Pareto" = "solid")) +

  # --- Formato del Eje X ---
  scale_x_continuous(labels = scales::number_format(big.mark = ".", decimal.mark = ",", accuracy = 1)) +
  labs(title = "Ajuste de distribuciones a las cuantías",
       x = "Valor de las Cuantías",
       y = "Densidad") +
  theme_minimal() +
  theme(legend.position = "right",
        legend.title = element_text(face = "bold"),
        legend.text = element_text(size = 10),
        axis.title.y = element_blank(), # Elimina el título del eje Y
        axis.text.y = element_blank(),  # Elimina los números/etiquetas del eje Y
        axis.ticks.y = element_blank(), # Elimina las marcas del eje Y
        axis.line.y = element_blank()  # Elimina la línea del eje Y)
   )+
  coord_cartesian(xlim = c(0, 2500000))
```

Optamos por una distribución Binomial Negativa para la frecuencia de siniestros por ser el caso más general para representar lo observado, ya que esta cubre los casos donde la variancia supera a la esperanza, situación frecuente en seguros de automóviles. 

Para las cuantías individuales de los siniestros, seleccionamos las dos distribuciones de cola pesada que muestran el mejor ajuste a nuestros datos: la Log-Normal, que modela adecuadamente la asimetría positiva y la Burr que captura diversos patrones de severidad, incluyendo eventos extremos. 

La estimación de parámetros para ambos modelos se hacen durante el ajuste de los mismos por el método de *máxima verosimilitud* y los resutados fueron:

* Binomial Negativa: $\hat{\mu}=3392,71$ y $\hat{\theta}=143,89$

* Log Normal: $\hat{log(\mu)}=12,95$ y $\hat{log(\sigma)}=0,3617$

* Burr: $\hat{\alpha}=1,08$, $\hat{\gamma}=4,68$ y $\hat{\beta}= 426007,2$

Primero usamos datos históricos de los últimos 3 años: cuántas pólizas tuvimos y cuántos siniestros ocurrieron. Con eso, calculamos la tasa de siniestralidad promedio (es decir, qué proporción de pólizas termina en un siniestro).

Luego, como para el año que viene esperamos tener una cantidad similar de pólizas, usamos esa tasa promedio para estimar cuántos siniestros podríamos tener. Pero en lugar de usar siempre un número fijo, lo que hicimos fue simular la cantidad de siniestros usando una distribución **Binomial Negativa**. Una vez que teníamos una cantidad simulada de siniestros para un año dado, simulamos también cuánto costaría cada uno. Y para eso usamos dos tipos distintos de distribuciones: **Burr** y **Log Normal**. Estas distribuciones reflejan bien las asimetrias de las cuantias observadas.

Simulados 10.000 valores del costo total anual de las cuantias a pagar, analizamos cuál sería un escenario muy desfavorable (el peor 1% de los casos), y a partir de eso, calculamos el **Margen de Seguridad Mínimo**. 

El margen de solvencia mínimo se calcula como la resta entre el valor que acumula una probabilidad del 99% en la distribución de la cuantia total (haciendo el supuseto de que la cuantia total se distribuyen Normal Power) y las primas totales a cobrar (las cuales pueden o no estar multiplicadas por un porcentaje de recargo).

Finalmente, presentamos los resultados recargando las primas en 1%, 1,5%, 2,5%, 5% o 10%.

```{r message=FALSE, warning=FALSE, include=FALSE}
# Cant sinistros 
## Binomial negativa
# Datos históricos
polizas <- c(24752, 25348, 25615)
siniestros <- c(3023, 3581, 3431)

tasas <- siniestros / polizas # Tasa siniestral por año
tasa_prom <- mean(tasas) # Media de la tasa siniestral
polizas_2024 <- 25615 # Simulación para 25615 pólizas
mu <- tasa_prom * polizas_2024
var_siniestros <- var(siniestros)
size <- mu^2 / (var_siniestros - mu)

# Simular 1000 observaciones de siniestros
set.seed(1511)# Cantidad de años a simular

# Cantidad de años a simular
n_sim <- 10000

# Vectores para guardar resultados
suma_burr <- numeric(n_sim)
suma_lnorm <- numeric(n_sim)

# Simulación año por año
for (i in 1:n_sim) {
  # Simular cantidad de siniestros
  cantidad <- rnbinom(1, mu = mu, size = size)

  # Simular severidades y sumar
  if (cantidad > 0) {
    burr_vals <- rburr(cantidad,
                       shape1 = ajuste_burr$estimate["shape1"],
                       shape2 = ajuste_burr$estimate["shape2"],
                       rate   = ajuste_burr$estimate["rate"])
    
    lnorm_vals <- rlnorm(cantidad,
                         meanlog = ajuste_lnorm$estimate["meanlog"],
                         sdlog   = ajuste_lnorm$estimate["sdlog"])
    
    suma_burr[i] <- sum(burr_vals)
    suma_lnorm[i] <- sum(lnorm_vals)
  } else {
    suma_burr[i] <- 0
    suma_lnorm[i] <- 0
  }
}

# Resultado final como data.frame
resultados <- data.frame(lognormal = suma_lnorm,
                         burr = suma_burr)


media <- mean(resultados$lognormal)
desvio <- sd(resultados$lognormal)
coef_asimetria <- skewness(resultados$lognormal)


z_99 <- qnorm(0.99, 0, 1)
y_99 <- z_99 + coef_asimetria/6 * (z_99^2-1)

y <- y_99* desvio + media

MSM_1porc <- y-(media*1.01)
MSM_1.5porc <- y-(media*1.015)
MSM_2.5porc <- y-(media*1.025)
MSM_5porc <- y-(media*1.05)
MSM_10porc <- y-(media*1.1)

MSM_log <- c(MSM_1porc, MSM_1.5porc, MSM_2.5porc,MSM_5porc,MSM_10porc)

media_burr <- mean(resultados$burr)
desvio_burr <- sd(resultados$burr)
coef_asimetria_burr <- skewness(resultados$burr)


z_99 <- qnorm(0.99, 0, 1)
y_99 <- z_99 + coef_asimetria_burr/6 * (z_99^2-1)

y <- y_99* desvio_burr + media_burr

MSM_1porc_burr <- y-(media_burr*1.01)
MSM_1.5porc_burr <- y-(media_burr*1.015)
MSM_2.5porc_burr <- y-(media_burr*1.025)
MSM_5porc_burr <- y-(media_burr*1.05)
MSM_10porc_burr <- y-(media_burr*1.1)
MSM_burr <- c(MSM_1porc_burr, MSM_1.5porc_burr, MSM_2.5porc_burr,MSM_5porc_burr,MSM_10porc_burr)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(e1071) # para skewness

# Cálculo de estadísticas
stats <- resultados %>%
  summarise(
    media_log = mean(lognormal),
    sd_log = sd(lognormal),
    skew_log = skewness(lognormal),
    p50_log = quantile(lognormal, 0.50),
    p75_log = quantile(lognormal, 0.75),
    p90_log = quantile(lognormal, 0.90),
    p95_log = quantile(lognormal, 0.95),
    p99_log = quantile(lognormal, 0.99),
    
    media_burr = mean(burr),
    sd_burr = sd(burr),
    skew_burr = skewness(burr),
    p50_burr = quantile(burr, 0.50),
    p75_burr = quantile(burr, 0.75),
    p90_burr = quantile(burr, 0.90),
    p95_burr = quantile(burr, 0.95),
    p99_burr = quantile(burr, 0.99)
  )

# Convertir a formato largo para graficar
resultados_long <- resultados %>%
  tidyr::pivot_longer(cols = everything(), names_to = "distribucion", values_to = "cuantia_total")

library(scales)  # para label_number

ggplot(resultados_long, aes(x = cuantia_total, fill = distribucion)) +
  geom_histogram(alpha = 0.6, position = "identity", bins = 100) +
  geom_vline(data = stats, aes(xintercept = media_log), color = "#2BAF9D", linetype = "dashed") +
  geom_vline(data = stats, aes(xintercept = media_burr), color = "#A870B4", linetype = "dashed") +
  labs(
    title = "Distribución de cuantías totales simuladas",
    x = "Cuantía total anual (en miles de millones)",
    y = "Frecuencia",
    fill = "Distribución"
  ) +
  scale_x_continuous(
    labels = label_number(scale = 1e-9, suffix = " mil M", accuracy = 0.1)
  ) +
  scale_fill_manual(values = c("lognormal" = "#2BAF9D", "burr" = "#A870B4")) +
  theme_minimal()

tabla1 <- data.frame(
  Distribución = c("Lognormal", "Burr"),
  Media = round(c(stats$media_log, stats$media_burr), 2),
  `Desvío estándar` = round(c(stats$sd_log, stats$sd_burr), 2),
  `Asimetría` = round(c(stats$skew_log, stats$skew_burr), 2),
  `Percentil 95` = round(c(stats$p95_log, stats$p95_burr), 2),
  `Percentil 99` = round(c(stats$p99_log, stats$p99_burr), 2)
)

# Aplicar el formato deseado a las columnas numéricas con formato monetario
columnas_monetarias <- c("Media", "Desvío.estándar", "Percentil.95", "Percentil.99")

# Usar `mutate` con `across` para aplicar la función a múltiples columnas
tabla1 <- tabla1 %>%
  mutate(across(.cols = all_of(columnas_monetarias),
                .fns = ~ paste0("$", formatC(.,
                                             big.mark = ".",
                                             decimal.mark = ",",
                                             format = "f",
                                             digits = 2)))) # Mantén 2 decimales para pesos si aplica
tabla1 <- tabla1 %>%
  mutate(across(.cols = "Asimetría",
                .fns = ~ paste0(formatC(.,
                                         big.mark = ".",
                                         decimal.mark = ",",
                                         format = "f",
                                         digits = 2)))) # Mantén 2 decimales para pesos si aplica

# Mostrar tabla en formato LaTeX
tabla1 %>%
  kbl(caption = "Estadísticas descriptivas de las cuantías anuales simuladas",
      align = "c",
      format = "latex",
      booktabs = TRUE,
      linesep = "") %>%
  kable_styling(latex_options = c("striped", "hold_position", "scale_down"),
                full_width = FALSE,
                position = "center",
                font_size = 10) %>%
  row_spec(0, background = "#66CDAA", bold = TRUE, color = "black") %>%
  column_spec(1, width = "4cm") %>%
  column_spec(2:6, width = "3cm") %>% # Asegúrate de que esto se ajuste al número de columnas
  footnote(general = "Nota: Valores expresados en pesos argentinos al 01/01/2024",
           general_title = "")

```


\newpage

# Resultados

A continuación presentamos los márgenes de solvencia mínimos obtenidos mediante simulación para diferentes porcentajes de recargo de seguridad, comparando los resultados bajo los dos modelos de severidad considerados: Log-Normal y Burr. La tabla resume los valores requeridos para garantizar un 99% de probabilidad de solvencia, mostrando cómo varían las necesidades de capital según el porcentaje de recargo aplicado y la distribución utilizada.

Los montos están expresados en pesos argentinos y representan el capital adicional que la compañía debería mantener para cubrir posibles desviaciones adversas en su cartera de seguros automotores durante el año 2024.
 
```{r echo=FALSE, message=FALSE, warning=FALSE}
library(kableExtra)
library(knitr)
porc <- c("1%", "1,5%","2,5%", "5%", "10%")
tabla1 <- data.frame(porc, MSM_log, MSM_burr)
# Formateo de la tabla
colnames(tabla1) <- c("Porcentaje de Recargo de Seguridad",
                     "Margen de Solvencia Mínimo Log-Normal", 
                     "Margen de Solvencia Mínimo Burr")

# Formateo de valores numéricos con separadores de miles
tabla1$`Margen de Solvencia Mínimo Log-Normal` <- paste0("$", formatC(tabla1$`Margen de Solvencia Mínimo Log-Normal`,
                                                                     big.mark = ".", 
                                                                     decimal.mark = ",",
                                                                     format = "f", 
                                                                     digits = 0))

tabla1$`Margen de Solvencia Mínimo Burr` <- paste0("$", formatC(tabla1$`Margen de Solvencia Mínimo Burr`,
                                                               big.mark = ".", 
                                                               decimal.mark = ",",
                                                               format = "f", 
                                                               digits = 0))

# Creación de la tabla con formato profesional
tabla1 %>%
  kbl(caption = "Margen de Solvencia Mínimo según porcentaje de recargo de seguridad",
      align = "c",
      format = "latex",
      booktabs = TRUE,
      linesep = "") %>%
  kable_styling(latex_options = c("striped", "hold_position", "scale_down"),
                full_width = FALSE,
                position = "center",
                font_size = 10) %>%
  row_spec(0, background = "#66CDAA", bold = TRUE, color = "black") %>%
  column_spec(1, width = "4cm") %>%
  column_spec(2:3, width = "5cm") %>%
  footnote(general = "Nota: Valores expresados en pesos argentinos al 01/01/2024",
           general_title = "")
```
 
En conclusión, observamos que a mayor recargo aplicado, menor es el capital que la compañía necesita reservar para garantizar su solvencia en el 99% de los escenarios posibles. Esta herramienta es ampliamente utilizada en la práctica actuarial, ya que permite dimensionar adecuadamente el riesgo. Sin embargo, es importante tener en cuenta que para atraer nuevos clientes es necesario ofrecer primas competitivas en relación con el resto del mercado. La determinación final de la prima que los productores comercializan surge, entonces, del equilibrio entre este análisis técnico, la presencia de marca y el contexto macroeconómico, entre otros factores.


\newpage

# Anexo
 
Se anexa el código utilizado.
 
```{r eval=FALSE, message=TRUE, warning=FALSE}

library(readxl)
library(dplyr)
library(fitdistrplus)
library(actuar)
library(ggplot2)
library(lubridate)
library(e1071)
library(knitr)
library(kableExtra)

cuantias_23 <- read_excel("Trabajo Final 2024 Base de Datos .xlsx", 
                          col_types = c("date", "numeric"))
cer23 <- read_excel("cer23.xlsx", 
                    col_types = c("date", "numeric"))


cuantias_23 <- cuantias_23 %>%
  left_join(cer23, by = "Fecha")

cuantias_23 <- cuantias_23 %>%
  mutate(cuantia24 = `Cuantia` * (cer23$ValorCER[366]/ValorCER))

tabla_cunatia <- cuantias_23
colnames(tabla_cunatia) <- c('Fecha','Cuantía', 'Valor CER', 'Cuantía Actualizada')
head(tabla_cunatia, 10)%>%
  kbl(caption = "Tabla 1: Cuantías Pagadas en 2023.", align = "c") %>% # Añadir un título
  kable_styling(bootstrap_options = "striped", full_width = FALSE) %>% 
  row_spec(0, background = "#66CDAA")




############################# DESCRIPTIVO #####################################

cuantias_23 <- cuantias_23 %>%
  mutate(mes = format(as.Date(Fecha), "%Y-%m"))
ggplot(cuantias_23, aes(x = mes)) +
  geom_bar(fill = "#66CDAA") +
  labs(title = "Cantidad de cuantías pagadas por mes (frecuencia)",
       x = "Mes",
       y = "Cantidad de pagos") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


####################

ggplot(cuantias_23, aes(x = cuantia24)) +
  geom_histogram(fill = "#66CDAA", bins = 60, color = "white") +
  labs(title = "Distribución de las cuantías actualizadas (severidad)",
       x = "Cuantía Actualizada",
       y = "Frecuencia") +
  theme_minimal()+
  coord_cartesian(xlim = c(0, 2000000))

datos <- na.omit(cuantias_23$cuantia24)

# Ajustes
ajuste_lnorm <- fitdist(datos, "lnorm")
ajuste_weibull <- fitdist(datos, "weibull")
ajuste_burr <- fitdist(datos, "burr", start = list(shape1 = 2, shape2 = 2, rate = 2))
ajuste_pareto <- fitdist(datos, "pareto", start = list(shape = 2, scale = min(datos)))


ggplot(data.frame(x = datos), aes(x = x)) +
  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = "#66CDAA", color = "black", alpha = 0.6) +

  # --- Todas las líneas en tipo "solid" (continua) y tamaño 0.7 (más fino) ---
  stat_function(fun = dlnorm,
                args = list(meanlog = ajuste_lnorm$estimate["meanlog"],
                            sdlog = ajuste_lnorm$estimate["sdlog"]),
                aes(color = "Log-normal", linetype = "Log-normal"),
                size = 0.7) + # Más fina
  stat_function(fun = dweibull,
                args = list(shape = ajuste_weibull$estimate["shape"],
                            scale = ajuste_weibull$estimate["scale"]),
                aes(color = "Weibull", linetype = "Weibull"),
                size = 0.7) + # Más fina
  stat_function(fun = dburr,
                args = list(shape1 = ajuste_burr$estimate["shape1"],
                            shape2 = ajuste_burr$estimate["shape2"],
                            rate = ajuste_burr$estimate["rate"]),
                aes(color = "Burr", linetype = "Burr"),
                size = 0.7) + # Más fina
  stat_function(fun = dpareto,
                args = list(shape = ajuste_pareto$estimate["shape"],
                            scale = ajuste_pareto$estimate["scale"]),
                aes(color = "Pareto", linetype = "Pareto"),
                size = 0.7) + # Más fina

  # --- Personalización de colores y tipos de línea en la leyenda ---
  scale_color_manual(name = "Distribución",
                     values = c("Log-normal" = "darkblue",
                                "Weibull" = "#5F9EA0",
                                "Burr" = "#8B0A50",
                                "Pareto" = "#CD5555")) +
  scale_linetype_manual(name = "Distribución",
                        values = c("Log-normal" = "solid", # Todas "solid"
                                   "Weibull" = "solid",
                                   "Burr" = "solid",
                                   "Pareto" = "solid")) +

  # --- Formato del Eje X ---
  scale_x_continuous(labels = scales::number_format(big.mark = ".", decimal.mark = ",", accuracy = 1)) +
  labs(title = "Ajuste de distribuciones a las cuantías",
       x = "Valor de las Cuantías",
       y = "Densidad") +
  theme_minimal() +
  theme(legend.position = "right",
        legend.title = element_text(face = "bold"),
        legend.text = element_text(size = 10),
        axis.title.y = element_blank(), # Elimina el título del eje Y
        axis.text.y = element_blank(),  # Elimina los números/etiquetas del eje Y
        axis.ticks.y = element_blank(), # Elimina las marcas del eje Y
        axis.line.y = element_blank()  # Elimina la línea del eje Y)
   )+
  coord_cartesian(xlim = c(0, 2500000))

########################### SIMULACION ##################################
# Cant sinistros 
## Binomial negativa
# Datos históricos
polizas <- c(24752, 25348, 25615)
siniestros <- c(3023, 3581, 3431)

tasas <- siniestros / polizas # Tasa siniestral por año
tasa_prom <- mean(tasas) # Media de la tasa siniestral
polizas_2024 <- 25615 # Simulación para 25615 pólizas
mu <- tasa_prom * polizas_2024
var_siniestros <- var(siniestros)
size <- mu^2 / (var_siniestros - mu)

# Simular 1000 observaciones de siniestros
set.seed(1511)# Cantidad de años a simular

# Cantidad de años a simular
n_sim <- 10000

# Vectores para guardar resultados
suma_burr <- numeric(n_sim)
suma_lnorm <- numeric(n_sim)

# Simulación año por año
for (i in 1:n_sim) {
  # Simular cantidad de siniestros
  cantidad <- rnbinom(1, mu = mu, size = size)

  # Simular severidades y sumar
  if (cantidad > 0) {
    burr_vals <- rburr(cantidad,
                       shape1 = ajuste_burr$estimate["shape1"],
                       shape2 = ajuste_burr$estimate["shape2"],
                       rate   = ajuste_burr$estimate["rate"])
    
    lnorm_vals <- rlnorm(cantidad,
                         meanlog = ajuste_lnorm$estimate["meanlog"],
                         sdlog   = ajuste_lnorm$estimate["sdlog"])
    
    suma_burr[i] <- sum(burr_vals)
    suma_lnorm[i] <- sum(lnorm_vals)
  } else {
    suma_burr[i] <- 0
    suma_lnorm[i] <- 0
  }
}

# Resultado final como data.frame
resultados <- data.frame(lognormal = suma_lnorm,
                         burr = suma_burr)


media <- mean(resultados$lognormal)
desvio <- sd(resultados$lognormal)
coef_asimetria <- skewness(resultados$lognormal)


z_99 <- qnorm(0.99, 0, 1)
y_99 <- z_99 + coef_asimetria/6 * (z_99^2-1)

y <- y_99* desvio + media

MSM_1porc <- y-(media*1.01)
MSM_1.5porc <- y-(media*1.015)
MSM_2.5porc <- y-(media*1.025)
MSM_5porc <- y-(media*1.05)
MSM_10porc <- y-(media*1.1)

MSM_log <- c(MSM_1porc, MSM_1.5porc, MSM_2.5porc,MSM_5porc,MSM_10porc)

media_burr <- mean(resultados$burr)
desvio_burr <- sd(resultados$burr)
coef_asimetria_burr <- skewness(resultados$burr)


z_99 <- qnorm(0.99, 0, 1)
y_99 <- z_99 + coef_asimetria_burr/6 * (z_99^2-1)

y <- y_99* desvio_burr + media_burr

MSM_1porc_burr <- y-(media_burr*1.01)
MSM_1.5porc_burr <- y-(media_burr*1.015)
MSM_2.5porc_burr <- y-(media_burr*1.025)
MSM_5porc_burr <- y-(media_burr*1.05)
MSM_10porc_burr <- y-(media_burr*1.1)
MSM_burr <- c(MSM_1porc_burr, MSM_1.5porc_burr, MSM_2.5porc_burr,MSM_5porc_burr,MSM_10porc_burr)


library(e1071) # para skewness

# Cálculo de estadísticas
stats <- resultados %>%
  summarise(
    media_log = mean(lognormal),
    sd_log = sd(lognormal),
    skew_log = skewness(lognormal),
    p50_log = quantile(lognormal, 0.50),
    p75_log = quantile(lognormal, 0.75),
    p90_log = quantile(lognormal, 0.90),
    p95_log = quantile(lognormal, 0.95),
    p99_log = quantile(lognormal, 0.99),
    
    media_burr = mean(burr),
    sd_burr = sd(burr),
    skew_burr = skewness(burr),
    p50_burr = quantile(burr, 0.50),
    p75_burr = quantile(burr, 0.75),
    p90_burr = quantile(burr, 0.90),
    p95_burr = quantile(burr, 0.95),
    p99_burr = quantile(burr, 0.99)
  )

# Convertir a formato largo para graficar
resultados_long <- resultados %>%
  tidyr::pivot_longer(cols = everything(), names_to = "distribucion", values_to = "cuantia_total")

library(scales)  # para label_number

ggplot(resultados_long, aes(x = cuantia_total, fill = distribucion)) +
  geom_histogram(alpha = 0.6, position = "identity", bins = 100) +
  geom_vline(data = stats, aes(xintercept = media_log), color = "#2BAF9D", linetype = "dashed") +
  geom_vline(data = stats, aes(xintercept = media_burr), color = "#A870B4", linetype = "dashed") +
  labs(
    title = "Distribución de cuantías totales simuladas",
    x = "Cuantía total anual (en miles de millones)",
    y = "Frecuencia",
    fill = "Distribución"
  ) +
  scale_x_continuous(
    labels = label_number(scale = 1e-9, suffix = " mil M", accuracy = 0.1)
  ) +
  scale_fill_manual(values = c("lognormal" = "#2BAF9D", "burr" = "#A870B4")) +
  theme_minimal()

tabla1 <- data.frame(
  Distribución = c("Lognormal", "Burr"),
  Media = round(c(stats$media_log, stats$media_burr), 2),
  `Desvío estándar` = round(c(stats$sd_log, stats$sd_burr), 2),
  `Asimetría` = round(c(stats$skew_log, stats$skew_burr), 2),
  `Percentil 95` = round(c(stats$p95_log, stats$p95_burr), 2),
  `Percentil 99` = round(c(stats$p99_log, stats$p99_burr), 2)
)

# Aplicar el formato deseado a las columnas numéricas con formato monetario
columnas_monetarias <- c("Media", "Desvío.estándar", "Percentil.95", "Percentil.99")

# Usar `mutate` con `across` para aplicar la función a múltiples columnas
tabla1 <- tabla1 %>%
  mutate(across(.cols = all_of(columnas_monetarias),
                .fns = ~ paste0("$", formatC(.,
                                             big.mark = ".",
                                             decimal.mark = ",",
                                             format = "f",
                                             digits = 2)))) # Mantén 2 decimales para pesos si aplica
tabla1 <- tabla1 %>%
  mutate(across(.cols = "Asimetría",
                .fns = ~ paste0(formatC(.,
                                         big.mark = ".",
                                         decimal.mark = ",",
                                         format = "f",
                                         digits = 2)))) # Mantén 2 decimales para pesos si aplica

# Mostrar tabla en formato LaTeX
tabla1 %>%
  kbl(caption = "Estadísticas descriptivas de las cuantías anuales simuladas",
      align = "c",
      format = "latex",
      booktabs = TRUE,
      linesep = "") %>%
  kable_styling(latex_options = c("striped", "hold_position", "scale_down"),
                full_width = FALSE,
                position = "center",
                font_size = 10) %>%
  row_spec(0, background = "#66CDAA", bold = TRUE, color = "black") %>%
  column_spec(1, width = "4cm") %>%
  column_spec(2:6, width = "3cm") %>% # Asegúrate de que esto se ajuste al número de columnas
  footnote(general = "Nota: Valores expresados en pesos argentinos al 01/01/2024",
           general_title = "")

############################## RESULTADOS ####################################

library(kableExtra)
library(knitr)
porc <- c("1%", "1,5%","2,5%", "5%", "10%")
tabla1 <- data.frame(porc, MSM_log, MSM_burr)
# Formateo de la tabla
colnames(tabla1) <- c("Porcentaje de Recargo de Seguridad",
                     "Margen de Solvencia Mínimo Log-Normal", 
                     "Margen de Solvencia Mínimo Burr")

# Formateo de valores numéricos con separadores de miles
tabla1$`Margen de Solvencia Mínimo Log-Normal` <- paste0("$", formatC(tabla1$`Margen de Solvencia Mínimo Log-Normal`,
                                                                     big.mark = ".", 
                                                                     decimal.mark = ",",
                                                                     format = "f", 
                                                                     digits = 0))

tabla1$`Margen de Solvencia Mínimo Burr` <- paste0("$", formatC(tabla1$`Margen de Solvencia Mínimo Burr`,
                                                               big.mark = ".", 
                                                               decimal.mark = ",",
                                                               format = "f", 
                                                               digits = 0))

# Creación de la tabla con formato profesional
tabla1 %>%
  kbl(caption = "Margen de Solvencia Mínimo según porcentaje de recargo de seguridad",
      align = "c",
      format = "latex",
      booktabs = TRUE,
      linesep = "") %>%
  kable_styling(latex_options = c("striped", "hold_position", "scale_down"),
                full_width = FALSE,
                position = "center",
                font_size = 10) %>%
  row_spec(0, background = "#66CDAA", bold = TRUE, color = "black") %>%
  column_spec(1, width = "4cm") %>%
  column_spec(2:3, width = "5cm") %>%
  footnote(general = "Nota: Valores expresados en pesos argentinos al 01/01/2024",
           general_title = "")

```
 
 